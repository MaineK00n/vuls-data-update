package exploitdb

import (
	"encoding/csv"
	"encoding/xml"
	"fmt"
	"io"
	"log"
	"net/http"
	"path/filepath"
	"slices"

	"github.com/cheggaaa/pb/v3"
	"github.com/pkg/errors"

	"github.com/MaineK00n/vuls-data-update/pkg/fetch/util"
	utilhttp "github.com/MaineK00n/vuls-data-update/pkg/fetch/util/http"
)

var exploitdbURL = ExploitDBURL{
	Exploits:   "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv",
	Shellcodes: "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_shellcodes.csv",
	Papers:     "https://gitlab.com/exploit-database/exploitdb-papers/-/raw/main/files_papers.csv",
	GHDB:       "https://gitlab.com/exploit-database/exploitdb/-/raw/main/ghdb.xml",
}

type options struct {
	exploitdbURL *ExploitDBURL
	dir          string
	retry        int
}

type Option interface {
	apply(*options)
}

type exploitdbURLOption struct {
	ExploitDBURL *ExploitDBURL
}

func (u exploitdbURLOption) apply(opts *options) {
	opts.exploitdbURL = u.ExploitDBURL
}

func WithExploitDBURL(url *ExploitDBURL) Option {
	return exploitdbURLOption{ExploitDBURL: url}
}

type dirOption string

func (d dirOption) apply(opts *options) {
	opts.dir = string(d)
}

func WithDir(dir string) Option {
	return dirOption(dir)
}

type retryOption int

func (r retryOption) apply(opts *options) {
	opts.retry = int(r)
}

func WithRetry(retry int) Option {
	return retryOption(retry)
}

func Fetch(opts ...Option) error {
	options := &options{
		exploitdbURL: &exploitdbURL,
		dir:          filepath.Join(util.CacheDir(), "fetch", "exploit", "exploitdb"),
		retry:        3,
	}

	for _, o := range opts {
		o.apply(options)
	}

	if err := util.RemoveAll(options.dir); err != nil {
		return errors.Wrapf(err, "remove %s", options.dir)
	}

	log.Println("[INFO] Fetch ExploitDB")

	log.Println(`[INFO] Exploits`)
	es, err := options.fetchExploits()
	if err != nil {
		return errors.Wrap(err, "fetch exploits")
	}
	bar := pb.StartNew(len(es))
	for _, e := range es {
		if err := util.Write(filepath.Join(options.dir, "exploits", fmt.Sprintf("%s.json", e.ID)), e); err != nil {
			return errors.Wrapf(err, "write %s", filepath.Join(options.dir, "exploits", fmt.Sprintf("%s.json", e.ID)))
		}

		bar.Increment()
	}
	bar.Finish()

	log.Println(`[INFO] Shellcodes`)
	ss, err := options.fetchShellcodes()
	if err != nil {
		return errors.Wrap(err, "fetch shellcodes")
	}
	bar = pb.StartNew(len(ss))
	for _, e := range ss {
		if err := util.Write(filepath.Join(options.dir, "shellcodes", fmt.Sprintf("%s.json", e.ID)), e); err != nil {
			return errors.Wrapf(err, "write %s", filepath.Join(options.dir, "shellcodes", fmt.Sprintf("%s.json", e.ID)))
		}

		bar.Increment()
	}
	bar.Finish()

	log.Println(`[INFO] Papers`)
	ps, err := options.fetchPapers()
	if err != nil {
		return errors.Wrap(err, "fetch papers")
	}
	bar = pb.StartNew(len(ps))
	for _, e := range ps {
		if err := util.Write(filepath.Join(options.dir, "papers", fmt.Sprintf("%s.json", e.ID)), e); err != nil {
			return errors.Wrapf(err, "write %s", filepath.Join(options.dir, "papers", fmt.Sprintf("%s.json", e.ID)))
		}

		bar.Increment()
	}
	bar.Finish()

	log.Println(`[INFO] GHDB`)
	ghdbs, err := options.fetchGHDB()
	if err != nil {
		return errors.Wrap(err, "fetch ghdb")
	}
	bar = pb.StartNew(len(ghdbs))
	for _, e := range ghdbs {
		if err := util.Write(filepath.Join(options.dir, "ghdb", fmt.Sprintf("%s.json", e.ID)), e); err != nil {
			return errors.Wrapf(err, "write %s", filepath.Join(options.dir, "ghdb", fmt.Sprintf("%s.json", e.ID)))
		}

		bar.Increment()
	}
	bar.Finish()

	return nil
}

func (opts options) fetchExploits() ([]Exploit, error) {
	resp, err := utilhttp.NewClient(utilhttp.WithClientRetryMax(opts.retry)).Get(opts.exploitdbURL.Exploits)
	if err != nil {
		return nil, errors.Wrap(err, "fetch exploits data")
	}
	defer resp.Body.Close() //nolint:errcheck

	if resp.StatusCode != http.StatusOK {
		_, _ = io.Copy(io.Discard, resp.Body)
		return nil, errors.Errorf("error response with status code %d", resp.StatusCode)
	}

	records, err := csv.NewReader(resp.Body).ReadAll()
	if err != nil {
		return nil, errors.Wrap(err, "read csv")
	}

	es := make([]Exploit, 0, len(records)-1)
	for i, r := range records {
		if i == 0 {
			header := []string{"id", "file", "description", "date_published", "author", "type", "platform", "port", "date_added", "date_updated", "verified", "codes", "tags", "aliases", "screenshot_url", "application_url", "source_url"}
			if !slices.Equal(r, header) {
				return nil, errors.Errorf("unexpected header. expected: %q, actual: %q", header, r)
			}
			continue
		}
		es = append(es, Exploit{
			ID:             r[0],
			File:           r[1],
			Description:    r[2],
			DatePublished:  r[3],
			Author:         r[4],
			Type:           r[5],
			Platform:       r[6],
			Port:           r[7],
			DateAdded:      r[8],
			DateUpdated:    r[9],
			Verified:       r[10],
			Codes:          r[11],
			Tags:           r[12],
			Aliases:        r[13],
			ScreenshotURL:  r[14],
			ApplicationURL: r[15],
			SourceURL:      r[16],
		})
	}
	return es, nil
}

func (opts options) fetchShellcodes() ([]Shellcode, error) {
	resp, err := utilhttp.NewClient(utilhttp.WithClientRetryMax(opts.retry)).Get(opts.exploitdbURL.Shellcodes)
	if err != nil {
		return nil, errors.Wrap(err, "fetch shellcodes data")
	}
	defer resp.Body.Close() //nolint:errcheck

	if resp.StatusCode != http.StatusOK {
		_, _ = io.Copy(io.Discard, resp.Body)
		return nil, errors.Errorf("error response with status code %d", resp.StatusCode)
	}

	records, err := csv.NewReader(resp.Body).ReadAll()
	if err != nil {
		return nil, errors.Wrap(err, "read csv")
	}

	es := make([]Shellcode, 0, len(records)-1)
	for i, r := range records {
		if i == 0 {
			header := []string{"id", "file", "description", "date_published", "author", "type", "platform", "size", "date_added", "date_updated", "verified", "codes", "tags", "aliases", "screenshot_url", "application_url", "source_url"}
			if !slices.Equal(r, header) {
				return nil, errors.Errorf("unexpected header. expected: %q, actual: %q", header, r)
			}
			continue
		}
		es = append(es, Shellcode{
			ID:             r[0],
			File:           r[1],
			Description:    r[2],
			DatePublished:  r[3],
			Author:         r[4],
			Type:           r[5],
			Platform:       r[6],
			Size:           r[7],
			DateAdded:      r[8],
			DateUpdated:    r[9],
			Verified:       r[10],
			Codes:          r[11],
			Tags:           r[12],
			Aliases:        r[13],
			ScreenshotURL:  r[14],
			ApplicationURL: r[15],
			SourceURL:      r[16],
		})
	}
	return es, nil
}

func (opts options) fetchPapers() ([]Paper, error) {
	resp, err := utilhttp.NewClient(utilhttp.WithClientRetryMax(opts.retry)).Get(opts.exploitdbURL.Papers)
	if err != nil {
		return nil, errors.Wrap(err, "fetch papers data")
	}
	defer resp.Body.Close() //nolint:errcheck

	if resp.StatusCode != http.StatusOK {
		_, _ = io.Copy(io.Discard, resp.Body)
		return nil, errors.Errorf("error response with status code %d", resp.StatusCode)
	}

	records, err := csv.NewReader(resp.Body).ReadAll()
	if err != nil {
		return nil, errors.Wrap(err, "read csv")
	}

	es := make([]Paper, 0, len(records)-1)
	for i, r := range records {
		if i == 0 {
			header := []string{"id", "file", "description", "date_published", "author", "type", "platform", "language", "date_added", "date_updated", "verified", "codes", "tags", "aliases", "screenshot_url", "application_url", "source_url"}
			if !slices.Equal(r, header) {
				return nil, errors.Errorf("unexpected header. expected: %q, actual: %q", header, r)
			}
			continue
		}
		es = append(es, Paper{
			ID:             r[0],
			File:           r[1],
			Description:    r[2],
			DatePublished:  r[3],
			Author:         r[4],
			Type:           r[5],
			Platform:       r[6],
			Language:       r[7],
			DateAdded:      r[8],
			DateUpdated:    r[9],
			Verified:       r[10],
			Codes:          r[11],
			Tags:           r[12],
			Aliases:        r[13],
			ScreenshotURL:  r[14],
			ApplicationURL: r[15],
			SourceURL:      r[16],
		})
	}
	return es, nil
}

func (opts options) fetchGHDB() ([]GHDB, error) {
	resp, err := utilhttp.NewClient(utilhttp.WithClientRetryMax(opts.retry)).Get(opts.exploitdbURL.GHDB)
	if err != nil {
		return nil, errors.Wrap(err, "fetch ghdb data")
	}
	defer resp.Body.Close() //nolint:errcheck

	if resp.StatusCode != http.StatusOK {
		_, _ = io.Copy(io.Discard, resp.Body)
		return nil, errors.Errorf("error response with status code %d", resp.StatusCode)
	}

	var root ghdb
	if err := xml.NewDecoder(resp.Body).Decode(&root); err != nil {
		return nil, errors.Wrap(err, "decode json")
	}
	return root.Entry, nil
}
